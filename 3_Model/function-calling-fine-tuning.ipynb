{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SFT Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty VRAM cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_type=\"microsoft/Phi-3-mini-4k-instruct\"\n",
    "# model_type=\"Qwen/Qwen2-0.5B\"\n",
    "# model_type=\"Qwen/Qwen2-1.5B\"\n",
    "model_type=\"VAGOsolutions/SauerkrautLM-1.5b\"\n",
    "output_model=\"function-calling-german-experiment\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the German SFT Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>function_name</th>\n",
       "      <th>command</th>\n",
       "      <th>parameters</th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>create_calendar_entry</td>\n",
       "      <td>Erstelle einen neuen Kalendareintrag für Vorle...</td>\n",
       "      <td>(\"Vorlesung Mittelhochdeutsch\", \"2023-03-09\", ...</td>\n",
       "      <td>Unten steht ein Befehl des Benutzer, bitte wäh...</td>\n",
       "      <td>&lt;oc_1&gt;(\"Vorlesung Mittelhochdeutsch\", \"2023-03...</td>\n",
       "      <td>Unten steht ein Befehl des Benutzer, bitte wäh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>create_calendar_entry</td>\n",
       "      <td>Plane Training im Fitnessstudio am 01.05.2023 ...</td>\n",
       "      <td>(\"Training im Fitnessstudio\", \"2023-05-01\", \"0...</td>\n",
       "      <td>Unten steht ein Befehl des Benutzer, bitte wäh...</td>\n",
       "      <td>&lt;oc_1&gt;(\"Training im Fitnessstudio\", \"2023-05-0...</td>\n",
       "      <td>Unten steht ein Befehl des Benutzer, bitte wäh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>create_calendar_entry</td>\n",
       "      <td>Trage Vorbesprechung Bachelorarbeit für den 14...</td>\n",
       "      <td>(\"Vorbesprechung Bachelorarbeit\", \"2023-07-14\"...</td>\n",
       "      <td>Unten steht ein Befehl des Benutzer, bitte wäh...</td>\n",
       "      <td>&lt;oc_1&gt;(\"Vorbesprechung Bachelorarbeit\", \"2023-...</td>\n",
       "      <td>Unten steht ein Befehl des Benutzer, bitte wäh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>create_calendar_entry</td>\n",
       "      <td>Plane Training im Fitnessstudio am 04. April 2...</td>\n",
       "      <td>(\"Training im Fitnessstudio\", \"2024-04-04\", \"1...</td>\n",
       "      <td>Unten steht ein Befehl des Benutzer, bitte wäh...</td>\n",
       "      <td>&lt;oc_1&gt;(\"Training im Fitnessstudio\", \"2024-04-0...</td>\n",
       "      <td>Unten steht ein Befehl des Benutzer, bitte wäh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>create_calendar_entry</td>\n",
       "      <td>Trage Lineare Algebra Übung für den 09. Mai 20...</td>\n",
       "      <td>(\"Lineare Algebra Übung\", \"2023-05-09\", \"23:20...</td>\n",
       "      <td>Unten steht ein Befehl des Benutzer, bitte wäh...</td>\n",
       "      <td>&lt;oc_1&gt;(\"Lineare Algebra Übung\", \"2023-05-09\", ...</td>\n",
       "      <td>Unten steht ein Befehl des Benutzer, bitte wäh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>list_calendar_entries</td>\n",
       "      <td>Zeige alle Termine am 31.07.2023 an</td>\n",
       "      <td>(\"2023-07-31\", False)</td>\n",
       "      <td>Unten steht ein Befehl des Benutzer, bitte wäh...</td>\n",
       "      <td>&lt;oc_3&gt;(\"2023-07-31\", False)&lt;oc_end&gt;\\nFunktions...</td>\n",
       "      <td>Unten steht ein Befehl des Benutzer, bitte wäh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>list_calendar_entries</td>\n",
       "      <td>Zeige mir alle noch ausstehenden Termine für d...</td>\n",
       "      <td>(\"2026-06-29\", True)</td>\n",
       "      <td>Unten steht ein Befehl des Benutzer, bitte wäh...</td>\n",
       "      <td>&lt;oc_3&gt;(\"2026-06-29\", True)&lt;oc_end&gt;\\nFunktionsb...</td>\n",
       "      <td>Unten steht ein Befehl des Benutzer, bitte wäh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>list_calendar_entries</td>\n",
       "      <td>Liste alle noch offene Termine am 06.06.2025 auf</td>\n",
       "      <td>(\"2025-06-06\", True)</td>\n",
       "      <td>Unten steht ein Befehl des Benutzer, bitte wäh...</td>\n",
       "      <td>&lt;oc_3&gt;(\"2025-06-06\", True)&lt;oc_end&gt;\\nFunktionsb...</td>\n",
       "      <td>Unten steht ein Befehl des Benutzer, bitte wäh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>list_calendar_entries</td>\n",
       "      <td>Zeige alle Termine am 28. Dezember 2024 an</td>\n",
       "      <td>(\"2024-12-28\", False)</td>\n",
       "      <td>Unten steht ein Befehl des Benutzer, bitte wäh...</td>\n",
       "      <td>&lt;oc_3&gt;(\"2024-12-28\", False)&lt;oc_end&gt;\\nFunktions...</td>\n",
       "      <td>Unten steht ein Befehl des Benutzer, bitte wäh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>list_calendar_entries</td>\n",
       "      <td>Zeige alle nicht beendete Termine am 17.06.202...</td>\n",
       "      <td>(\"2022-06-17\", True)</td>\n",
       "      <td>Unten steht ein Befehl des Benutzer, bitte wäh...</td>\n",
       "      <td>&lt;oc_3&gt;(\"2022-06-17\", True)&lt;oc_end&gt;\\nFunktionsb...</td>\n",
       "      <td>Unten steht ein Befehl des Benutzer, bitte wäh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              function_name  \\\n",
       "0     create_calendar_entry   \n",
       "1     create_calendar_entry   \n",
       "2     create_calendar_entry   \n",
       "3     create_calendar_entry   \n",
       "4     create_calendar_entry   \n",
       "...                     ...   \n",
       "2995  list_calendar_entries   \n",
       "2996  list_calendar_entries   \n",
       "2997  list_calendar_entries   \n",
       "2998  list_calendar_entries   \n",
       "2999  list_calendar_entries   \n",
       "\n",
       "                                                command  \\\n",
       "0     Erstelle einen neuen Kalendareintrag für Vorle...   \n",
       "1     Plane Training im Fitnessstudio am 01.05.2023 ...   \n",
       "2     Trage Vorbesprechung Bachelorarbeit für den 14...   \n",
       "3     Plane Training im Fitnessstudio am 04. April 2...   \n",
       "4     Trage Lineare Algebra Übung für den 09. Mai 20...   \n",
       "...                                                 ...   \n",
       "2995                Zeige alle Termine am 31.07.2023 an   \n",
       "2996  Zeige mir alle noch ausstehenden Termine für d...   \n",
       "2997   Liste alle noch offene Termine am 06.06.2025 auf   \n",
       "2998         Zeige alle Termine am 28. Dezember 2024 an   \n",
       "2999  Zeige alle nicht beendete Termine am 17.06.202...   \n",
       "\n",
       "                                             parameters  \\\n",
       "0     (\"Vorlesung Mittelhochdeutsch\", \"2023-03-09\", ...   \n",
       "1     (\"Training im Fitnessstudio\", \"2023-05-01\", \"0...   \n",
       "2     (\"Vorbesprechung Bachelorarbeit\", \"2023-07-14\"...   \n",
       "3     (\"Training im Fitnessstudio\", \"2024-04-04\", \"1...   \n",
       "4     (\"Lineare Algebra Übung\", \"2023-05-09\", \"23:20...   \n",
       "...                                                 ...   \n",
       "2995                              (\"2023-07-31\", False)   \n",
       "2996                               (\"2026-06-29\", True)   \n",
       "2997                               (\"2025-06-06\", True)   \n",
       "2998                              (\"2024-12-28\", False)   \n",
       "2999                               (\"2022-06-17\", True)   \n",
       "\n",
       "                                                 prompt  \\\n",
       "0     Unten steht ein Befehl des Benutzer, bitte wäh...   \n",
       "1     Unten steht ein Befehl des Benutzer, bitte wäh...   \n",
       "2     Unten steht ein Befehl des Benutzer, bitte wäh...   \n",
       "3     Unten steht ein Befehl des Benutzer, bitte wäh...   \n",
       "4     Unten steht ein Befehl des Benutzer, bitte wäh...   \n",
       "...                                                 ...   \n",
       "2995  Unten steht ein Befehl des Benutzer, bitte wäh...   \n",
       "2996  Unten steht ein Befehl des Benutzer, bitte wäh...   \n",
       "2997  Unten steht ein Befehl des Benutzer, bitte wäh...   \n",
       "2998  Unten steht ein Befehl des Benutzer, bitte wäh...   \n",
       "2999  Unten steht ein Befehl des Benutzer, bitte wäh...   \n",
       "\n",
       "                                             completion  \\\n",
       "0     <oc_1>(\"Vorlesung Mittelhochdeutsch\", \"2023-03...   \n",
       "1     <oc_1>(\"Training im Fitnessstudio\", \"2023-05-0...   \n",
       "2     <oc_1>(\"Vorbesprechung Bachelorarbeit\", \"2023-...   \n",
       "3     <oc_1>(\"Training im Fitnessstudio\", \"2024-04-0...   \n",
       "4     <oc_1>(\"Lineare Algebra Übung\", \"2023-05-09\", ...   \n",
       "...                                                 ...   \n",
       "2995  <oc_3>(\"2023-07-31\", False)<oc_end>\\nFunktions...   \n",
       "2996  <oc_3>(\"2026-06-29\", True)<oc_end>\\nFunktionsb...   \n",
       "2997  <oc_3>(\"2025-06-06\", True)<oc_end>\\nFunktionsb...   \n",
       "2998  <oc_3>(\"2024-12-28\", False)<oc_end>\\nFunktions...   \n",
       "2999  <oc_3>(\"2022-06-17\", True)<oc_end>\\nFunktionsb...   \n",
       "\n",
       "                                                   text  \n",
       "0     Unten steht ein Befehl des Benutzer, bitte wäh...  \n",
       "1     Unten steht ein Befehl des Benutzer, bitte wäh...  \n",
       "2     Unten steht ein Befehl des Benutzer, bitte wäh...  \n",
       "3     Unten steht ein Befehl des Benutzer, bitte wäh...  \n",
       "4     Unten steht ein Befehl des Benutzer, bitte wäh...  \n",
       "...                                                 ...  \n",
       "2995  Unten steht ein Befehl des Benutzer, bitte wäh...  \n",
       "2996  Unten steht ein Befehl des Benutzer, bitte wäh...  \n",
       "2997  Unten steht ein Befehl des Benutzer, bitte wäh...  \n",
       "2998  Unten steht ein Befehl des Benutzer, bitte wäh...  \n",
       "2999  Unten steht ein Befehl des Benutzer, bitte wäh...  \n",
       "\n",
       "[3000 rows x 6 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset_df = pd.read_csv(\"function_calling_dataset.csv\", sep=\";\")\n",
    "dataset_df = pd.read_csv(\"german-dataset.csv\", sep=\";\")\n",
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Unten steht ein Befehl des Benutzer, bitte wäh...\n",
       "1       Unten steht ein Befehl des Benutzer, bitte wäh...\n",
       "2       Unten steht ein Befehl des Benutzer, bitte wäh...\n",
       "3       Unten steht ein Befehl des Benutzer, bitte wäh...\n",
       "4       Unten steht ein Befehl des Benutzer, bitte wäh...\n",
       "                              ...                        \n",
       "2995    Below is the query from the users, please choo...\n",
       "2996    Below is the query from the users, please choo...\n",
       "2997    Below is the query from the users, please choo...\n",
       "2998    Below is the query from the users, please choo...\n",
       "2999    Below is the query from the users, please choo...\n",
       "Name: text, Length: 6000, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df[\"text\"] = dataset_df[\"prompt\"] + dataset_df[\"completion\"]\n",
    "dataset_df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_name': 'create_calendar_entry',\n",
       " 'command': 'Erstelle einen neuen Kalendareintrag für Vorlesung Mittelhochdeutsch am 09.03.2023 um 7 Uhr für 1,5 Stunden',\n",
       " 'parameters': '(\"Vorlesung Mittelhochdeutsch\", \"2023-03-09\", \"07:00\", 90)',\n",
       " 'prompt': 'Unten steht ein Befehl des Benutzer, bitte wähle die korrekte Funktion aus und generiere Parameter, um die Funktion aufzurufen.\\nBefehl: Erstelle einen neuen Kalendareintrag für Vorlesung Mittelhochdeutsch am 09.03.2023 um 7 Uhr für 1,5 Stunden\\nAntwort: ',\n",
       " 'completion': '<oc_1>(\"Vorlesung Mittelhochdeutsch\", \"2023-03-09\", \"07:00\", 90)<oc_end>\\nFunktionsbeschreibung: def create_calender_entry(title, date, time, duration):\\n\"\"\"\\nErstellt einen Kalendereintrag mit den angegebenen Details und ruft die Kalender-API auf.\\n\\nParameter:\\ntitle (str): Der Titel des Kalendereintrags.\\ndate (str): Das Datum des Kalendereintrags im Format \\'YYYY-MM-DD\\'.\\ntime (str): Die Uhrzeit des Kalendereintrags im Format \\'HH:MM\\'.\\nduration (int): Die Dauer des Kalendereintrags in Minuten.\\n\\nRückgabe:\\nbool: True, wenn der Aufruf der Kalender-API erfolgreich war, andernfalls False.\\n\"\"\"',\n",
       " 'text': 'Unten steht ein Befehl des Benutzer, bitte wähle die korrekte Funktion aus und generiere Parameter, um die Funktion aufzurufen.\\nBefehl: Erstelle einen neuen Kalendareintrag für Vorlesung Mittelhochdeutsch am 09.03.2023 um 7 Uhr für 1,5 Stunden\\nAntwort: <oc_1>(\"Vorlesung Mittelhochdeutsch\", \"2023-03-09\", \"07:00\", 90)<oc_end>\\nFunktionsbeschreibung: def create_calender_entry(title, date, time, duration):\\n\"\"\"\\nErstellt einen Kalendereintrag mit den angegebenen Details und ruft die Kalender-API auf.\\n\\nParameter:\\ntitle (str): Der Titel des Kalendereintrags.\\ndate (str): Das Datum des Kalendereintrags im Format \\'YYYY-MM-DD\\'.\\ntime (str): Die Uhrzeit des Kalendereintrags im Format \\'HH:MM\\'.\\nduration (int): Die Dauer des Kalendereintrags in Minuten.\\n\\nRückgabe:\\nbool: True, wenn der Aufruf der Kalender-API erfolgreich war, andernfalls False.\\n\"\"\"',\n",
       " '__index_level_0__': 0}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(dataset_df)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Base Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_type)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_type, device_map=\"auto\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 1536)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2SdpaAttention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm()\n",
       "        (post_attention_layernorm): Qwen2RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add custom Special Tokens (Functional Tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151646"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.encode('<oc_1>(\"Team Sync\", \"2024-06-20\", \"10:00\", 60)<oc_end>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<oc_1>', '<oc_2>', '<oc_3>', '<oc_end>'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokens = [\"<oc_1>\", \"<oc_2>\", \"<oc_3>\", \"<oc_end>\"]\n",
    "new_tokens = set(new_tokens) - set(tokenizer.vocab.keys())\n",
    "new_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapt Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(151650, 1536)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_tokens(list(new_tokens))\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add PAD Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151650"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.encode('<oc_1>(\"Team Sync\", \"2024-06-20\", \"10:00\", 60)<oc_end>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/fine-tuning/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/ubuntu/fine-tuning/.venv/lib/python3.10/site-packages/transformers/training_args.py:1965: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of 🤗 Transformers. Use `--hub_token` instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/fine-tuning/.venv/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:278: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "/home/ubuntu/fine-tuning/.venv/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:307: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 6000/6000 [00:00<00:00, 8831.58 examples/s]\n",
      "/home/ubuntu/fine-tuning/.venv/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:397: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "[codecarbon INFO @ 21:56:03] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 21:56:03] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 21:56:03] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 21:56:03] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 21:56:03] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon WARNING @ 21:56:04] We saw that you have a Intel Xeon Processor (Icelake) but we don't know it. Please contact us.\n",
      "[codecarbon INFO @ 21:56:04] CPU Model on constant consumption mode: Intel Xeon Processor (Icelake)\n",
      "[codecarbon INFO @ 21:56:04] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 21:56:04]   Platform system: Linux-5.15.0-112-generic-x86_64-with-glibc2.35\n",
      "[codecarbon INFO @ 21:56:04]   Python version: 3.10.12\n",
      "[codecarbon INFO @ 21:56:04]   CodeCarbon version: 2.3.5\n",
      "[codecarbon INFO @ 21:56:04]   Available RAM : 31.337 GB\n",
      "[codecarbon INFO @ 21:56:04]   CPU count: 16\n",
      "[codecarbon INFO @ 21:56:04]   CPU model: Intel Xeon Processor (Icelake)\n",
      "[codecarbon INFO @ 21:56:04]   GPU count: 1\n",
      "[codecarbon INFO @ 21:56:04]   GPU model: 1 x NVIDIA A40\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4500' max='4500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4500/4500 29:57, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.209000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.403500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.233600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.198900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.191700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.190300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.155500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.189700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.154700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.189900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.148700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.214800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.142700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.164900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.149300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.147100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.153300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.135300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.152900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.133300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.129900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.123300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.162000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.138200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.156000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.135100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.163600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.134500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.141000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.134100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.154000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.109800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.139200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.115700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.164300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.132500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.127900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.120900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.145900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.161500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.150300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.141900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.124300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.141000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.122200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.143100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.111900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.115900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.126800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.122800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.139400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.138000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.143100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.143500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.118500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.122800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.122300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.126700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.097100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.115000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.123300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.138000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.111000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.112300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.118100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.116500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.117300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.121900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.120300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.120400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.117500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.132700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.114300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.102000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.119400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.150600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.126800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.117600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.133800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.122200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.112900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.135400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.131900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.122200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0.116400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.120800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>0.107800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.129300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.117600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.120600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.114600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.145400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>0.128900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.125600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>0.120300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.116600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.113900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>0.155700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.147800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.126900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>0.104000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>0.118400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.117100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>0.127800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.115000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>0.114400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.116000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>0.130100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.104800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.115700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.135500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>0.128100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.101200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>0.124800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.134300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>0.117700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>0.109200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>0.113700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>0.120100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.117400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.123100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>0.117500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.108100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>0.123300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.115300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1310</td>\n",
       "      <td>0.116300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.135100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1330</td>\n",
       "      <td>0.117200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>0.131600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.126700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>0.125700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1370</td>\n",
       "      <td>0.107000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.113400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1390</td>\n",
       "      <td>0.102300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.112000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1410</td>\n",
       "      <td>0.108000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420</td>\n",
       "      <td>0.117400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1430</td>\n",
       "      <td>0.103500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.092200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.126500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1460</td>\n",
       "      <td>0.137300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1470</td>\n",
       "      <td>0.115200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480</td>\n",
       "      <td>0.110400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1490</td>\n",
       "      <td>0.112200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.112200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1510</td>\n",
       "      <td>0.123900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1520</td>\n",
       "      <td>0.113400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1530</td>\n",
       "      <td>0.116500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1540</td>\n",
       "      <td>0.106500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.128900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.104000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1570</td>\n",
       "      <td>0.119300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1580</td>\n",
       "      <td>0.121800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1590</td>\n",
       "      <td>0.113200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.098000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1610</td>\n",
       "      <td>0.096100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.125200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1630</td>\n",
       "      <td>0.126300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1640</td>\n",
       "      <td>0.120300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.124600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1660</td>\n",
       "      <td>0.106600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1670</td>\n",
       "      <td>0.107300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.122500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1690</td>\n",
       "      <td>0.103200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.121600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1710</td>\n",
       "      <td>0.125400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1720</td>\n",
       "      <td>0.103000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1730</td>\n",
       "      <td>0.107000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.124200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.106100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1760</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1770</td>\n",
       "      <td>0.105500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1780</td>\n",
       "      <td>0.111700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1790</td>\n",
       "      <td>0.118200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.110900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1810</td>\n",
       "      <td>0.092900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1820</td>\n",
       "      <td>0.116400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1830</td>\n",
       "      <td>0.096600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1840</td>\n",
       "      <td>0.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.111200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.107500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1870</td>\n",
       "      <td>0.118100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1880</td>\n",
       "      <td>0.104100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1890</td>\n",
       "      <td>0.118200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.116200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1910</td>\n",
       "      <td>0.109600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.123600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1930</td>\n",
       "      <td>0.112700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1940</td>\n",
       "      <td>0.107800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.122000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1960</td>\n",
       "      <td>0.119200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1970</td>\n",
       "      <td>0.114300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.121000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1990</td>\n",
       "      <td>0.112600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.126300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2010</td>\n",
       "      <td>0.099800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020</td>\n",
       "      <td>0.117500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2030</td>\n",
       "      <td>0.122800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2040</td>\n",
       "      <td>0.126200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.094900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2060</td>\n",
       "      <td>0.108400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2070</td>\n",
       "      <td>0.114200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2080</td>\n",
       "      <td>0.133400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2090</td>\n",
       "      <td>0.114100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.116500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2110</td>\n",
       "      <td>0.110200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2120</td>\n",
       "      <td>0.115600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2130</td>\n",
       "      <td>0.127500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2140</td>\n",
       "      <td>0.109400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.105900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2160</td>\n",
       "      <td>0.108300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2170</td>\n",
       "      <td>0.122800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2180</td>\n",
       "      <td>0.126500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2190</td>\n",
       "      <td>0.097600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.106100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2210</td>\n",
       "      <td>0.126800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2220</td>\n",
       "      <td>0.120700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2230</td>\n",
       "      <td>0.121600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2240</td>\n",
       "      <td>0.120100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.134900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2260</td>\n",
       "      <td>0.113200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2270</td>\n",
       "      <td>0.125900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2280</td>\n",
       "      <td>0.077500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2290</td>\n",
       "      <td>0.101100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.113800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2310</td>\n",
       "      <td>0.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2320</td>\n",
       "      <td>0.133100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2330</td>\n",
       "      <td>0.110200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2340</td>\n",
       "      <td>0.135200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.118200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2360</td>\n",
       "      <td>0.103900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2370</td>\n",
       "      <td>0.126400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2380</td>\n",
       "      <td>0.116100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2390</td>\n",
       "      <td>0.123500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.116500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2410</td>\n",
       "      <td>0.114400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2420</td>\n",
       "      <td>0.113700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2430</td>\n",
       "      <td>0.131900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2440</td>\n",
       "      <td>0.112400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.114100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2460</td>\n",
       "      <td>0.111300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2470</td>\n",
       "      <td>0.108600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2480</td>\n",
       "      <td>0.114100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2490</td>\n",
       "      <td>0.132100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.117800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2510</td>\n",
       "      <td>0.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2520</td>\n",
       "      <td>0.120200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2530</td>\n",
       "      <td>0.105500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2540</td>\n",
       "      <td>0.119700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.117900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2560</td>\n",
       "      <td>0.107000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2570</td>\n",
       "      <td>0.117200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2580</td>\n",
       "      <td>0.115100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2590</td>\n",
       "      <td>0.103300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.119000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2610</td>\n",
       "      <td>0.112300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2620</td>\n",
       "      <td>0.103100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2630</td>\n",
       "      <td>0.115500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2640</td>\n",
       "      <td>0.116600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>0.138600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2660</td>\n",
       "      <td>0.107000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2670</td>\n",
       "      <td>0.126900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2680</td>\n",
       "      <td>0.109100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2690</td>\n",
       "      <td>0.112800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.106100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2710</td>\n",
       "      <td>0.101900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2720</td>\n",
       "      <td>0.111300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2730</td>\n",
       "      <td>0.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2740</td>\n",
       "      <td>0.110800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.118400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2760</td>\n",
       "      <td>0.117000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2770</td>\n",
       "      <td>0.096700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2780</td>\n",
       "      <td>0.107100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2790</td>\n",
       "      <td>0.098200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.149600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2810</td>\n",
       "      <td>0.111800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2820</td>\n",
       "      <td>0.117400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2830</td>\n",
       "      <td>0.093800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2840</td>\n",
       "      <td>0.115100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>0.119600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2860</td>\n",
       "      <td>0.120300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2870</td>\n",
       "      <td>0.111700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2880</td>\n",
       "      <td>0.119300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2890</td>\n",
       "      <td>0.110300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.123200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2910</td>\n",
       "      <td>0.117300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2920</td>\n",
       "      <td>0.113500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2930</td>\n",
       "      <td>0.125900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2940</td>\n",
       "      <td>0.114200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>0.101200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2960</td>\n",
       "      <td>0.104800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2970</td>\n",
       "      <td>0.108000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2980</td>\n",
       "      <td>0.103400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2990</td>\n",
       "      <td>0.101900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3010</td>\n",
       "      <td>0.105800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3020</td>\n",
       "      <td>0.100900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3030</td>\n",
       "      <td>0.136700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3040</td>\n",
       "      <td>0.118300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>0.097700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3060</td>\n",
       "      <td>0.099000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3070</td>\n",
       "      <td>0.119100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3080</td>\n",
       "      <td>0.111400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3090</td>\n",
       "      <td>0.115900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.110300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3110</td>\n",
       "      <td>0.110400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3120</td>\n",
       "      <td>0.118900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3130</td>\n",
       "      <td>0.111500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3140</td>\n",
       "      <td>0.117000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.115500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3160</td>\n",
       "      <td>0.103400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3170</td>\n",
       "      <td>0.120800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3180</td>\n",
       "      <td>0.114500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3190</td>\n",
       "      <td>0.111000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.133200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3210</td>\n",
       "      <td>0.122500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3220</td>\n",
       "      <td>0.090800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3230</td>\n",
       "      <td>0.125200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3240</td>\n",
       "      <td>0.134900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.118700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3260</td>\n",
       "      <td>0.119400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3270</td>\n",
       "      <td>0.112900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3280</td>\n",
       "      <td>0.131300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3290</td>\n",
       "      <td>0.125200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.137100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3310</td>\n",
       "      <td>0.137300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3320</td>\n",
       "      <td>0.104400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3330</td>\n",
       "      <td>0.108500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3340</td>\n",
       "      <td>0.102100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>0.127200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3360</td>\n",
       "      <td>0.120600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3370</td>\n",
       "      <td>0.094700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3380</td>\n",
       "      <td>0.106300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3390</td>\n",
       "      <td>0.100600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.102300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3410</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3420</td>\n",
       "      <td>0.102300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3430</td>\n",
       "      <td>0.120100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3440</td>\n",
       "      <td>0.112400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>0.107000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3460</td>\n",
       "      <td>0.126700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3470</td>\n",
       "      <td>0.132000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3480</td>\n",
       "      <td>0.110600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3490</td>\n",
       "      <td>0.129100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.097300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3510</td>\n",
       "      <td>0.116400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3520</td>\n",
       "      <td>0.122700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3530</td>\n",
       "      <td>0.121000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3540</td>\n",
       "      <td>0.129900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>0.106900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3560</td>\n",
       "      <td>0.106100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3570</td>\n",
       "      <td>0.099700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3580</td>\n",
       "      <td>0.096500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3590</td>\n",
       "      <td>0.119500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.104900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3610</td>\n",
       "      <td>0.121700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3620</td>\n",
       "      <td>0.108100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3630</td>\n",
       "      <td>0.117300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3640</td>\n",
       "      <td>0.124700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>0.118000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3660</td>\n",
       "      <td>0.111300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3670</td>\n",
       "      <td>0.117200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3680</td>\n",
       "      <td>0.115800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3690</td>\n",
       "      <td>0.119100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.102000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3710</td>\n",
       "      <td>0.105600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3720</td>\n",
       "      <td>0.101600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3730</td>\n",
       "      <td>0.108900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3740</td>\n",
       "      <td>0.118000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.106400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3760</td>\n",
       "      <td>0.118900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3770</td>\n",
       "      <td>0.096300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3780</td>\n",
       "      <td>0.106600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3790</td>\n",
       "      <td>0.120900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.098200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3810</td>\n",
       "      <td>0.105500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3820</td>\n",
       "      <td>0.103900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3830</td>\n",
       "      <td>0.092300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3840</td>\n",
       "      <td>0.125300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>0.099900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3860</td>\n",
       "      <td>0.104800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3870</td>\n",
       "      <td>0.111600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3880</td>\n",
       "      <td>0.120600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3890</td>\n",
       "      <td>0.105300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.111100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3910</td>\n",
       "      <td>0.101200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3920</td>\n",
       "      <td>0.101800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3930</td>\n",
       "      <td>0.086200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3940</td>\n",
       "      <td>0.110700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>0.128900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3960</td>\n",
       "      <td>0.125500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3970</td>\n",
       "      <td>0.112900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3980</td>\n",
       "      <td>0.095600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3990</td>\n",
       "      <td>0.100300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.087200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4010</td>\n",
       "      <td>0.114300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4020</td>\n",
       "      <td>0.115700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4030</td>\n",
       "      <td>0.112200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4040</td>\n",
       "      <td>0.118900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>0.094100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4060</td>\n",
       "      <td>0.106600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4070</td>\n",
       "      <td>0.137400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4080</td>\n",
       "      <td>0.113000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4090</td>\n",
       "      <td>0.100500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.099700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4110</td>\n",
       "      <td>0.112500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4120</td>\n",
       "      <td>0.101200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4130</td>\n",
       "      <td>0.114700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4140</td>\n",
       "      <td>0.100100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4150</td>\n",
       "      <td>0.099800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4160</td>\n",
       "      <td>0.120500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4170</td>\n",
       "      <td>0.102300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4180</td>\n",
       "      <td>0.090600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4190</td>\n",
       "      <td>0.108300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.102900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4210</td>\n",
       "      <td>0.094800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4220</td>\n",
       "      <td>0.119900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4230</td>\n",
       "      <td>0.107300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4240</td>\n",
       "      <td>0.099000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>0.105300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4260</td>\n",
       "      <td>0.113900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4270</td>\n",
       "      <td>0.112200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4280</td>\n",
       "      <td>0.119500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4290</td>\n",
       "      <td>0.106400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.105800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4310</td>\n",
       "      <td>0.111500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4320</td>\n",
       "      <td>0.105700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4330</td>\n",
       "      <td>0.112500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4340</td>\n",
       "      <td>0.102600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>0.116200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4360</td>\n",
       "      <td>0.111900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4370</td>\n",
       "      <td>0.098300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4380</td>\n",
       "      <td>0.126400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4390</td>\n",
       "      <td>0.107900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.124400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4410</td>\n",
       "      <td>0.108600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4420</td>\n",
       "      <td>0.114400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4430</td>\n",
       "      <td>0.108700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4440</td>\n",
       "      <td>0.084200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4450</td>\n",
       "      <td>0.112800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4460</td>\n",
       "      <td>0.106500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4470</td>\n",
       "      <td>0.111600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4480</td>\n",
       "      <td>0.089000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4490</td>\n",
       "      <td>0.112800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.109700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:56:21] Energy consumed for RAM : 0.000049 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 21:56:21] Energy consumed for all GPUs : 0.001009 kWh. Total GPU Power : 242.0692581750781 W\n",
      "[codecarbon INFO @ 21:56:21] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 21:56:21] 0.001235 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 21:56:36] Energy consumed for RAM : 0.000098 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 21:56:36] Energy consumed for all GPUs : 0.002047 kWh. Total GPU Power : 249.1887408818675 W\n",
      "[codecarbon INFO @ 21:56:36] Energy consumed for all CPUs : 0.000354 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 21:56:36] 0.002499 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 21:56:51] Energy consumed for RAM : 0.000147 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 21:56:51] Energy consumed for all GPUs : 0.003084 kWh. Total GPU Power : 248.98157254413871 W\n",
      "[codecarbon INFO @ 21:56:51] Energy consumed for all CPUs : 0.000532 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 21:56:51] 0.003763 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 21:57:06] Energy consumed for RAM : 0.000196 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 21:57:06] Energy consumed for all GPUs : 0.004144 kWh. Total GPU Power : 254.55531841311284 W\n",
      "[codecarbon INFO @ 21:57:06] Energy consumed for all CPUs : 0.000709 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 21:57:06] 0.005048 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 21:57:21] Energy consumed for RAM : 0.000245 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 21:57:21] Energy consumed for all GPUs : 0.005203 kWh. Total GPU Power : 254.27264819302425 W\n",
      "[codecarbon INFO @ 21:57:21] Energy consumed for all CPUs : 0.000886 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 21:57:21] 0.006333 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 21:57:36] Energy consumed for RAM : 0.000294 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 21:57:36] Energy consumed for all GPUs : 0.006281 kWh. Total GPU Power : 258.9828323894509 W\n",
      "[codecarbon INFO @ 21:57:36] Energy consumed for all CPUs : 0.001063 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 21:57:36] 0.007638 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 21:57:51] Energy consumed for RAM : 0.000343 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 21:57:51] Energy consumed for all GPUs : 0.007352 kWh. Total GPU Power : 257.24377663648886 W\n",
      "[codecarbon INFO @ 21:57:51] Energy consumed for all CPUs : 0.001240 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 21:57:51] 0.008935 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 21:58:06] Energy consumed for RAM : 0.000391 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 21:58:06] Energy consumed for all GPUs : 0.008433 kWh. Total GPU Power : 259.49183736082557 W\n",
      "[codecarbon INFO @ 21:58:06] Energy consumed for all CPUs : 0.001417 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 21:58:06] 0.010241 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 21:58:21] Energy consumed for RAM : 0.000441 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 21:58:21] Energy consumed for all GPUs : 0.009521 kWh. Total GPU Power : 260.4588311857065 W\n",
      "[codecarbon INFO @ 21:58:21] Energy consumed for all CPUs : 0.001594 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 21:58:21] 0.011556 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 21:58:36] Energy consumed for RAM : 0.000489 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 21:58:36] Energy consumed for all GPUs : 0.010600 kWh. Total GPU Power : 259.0614304528285 W\n",
      "[codecarbon INFO @ 21:58:36] Energy consumed for all CPUs : 0.001771 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 21:58:36] 0.012861 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 21:58:51] Energy consumed for RAM : 0.000538 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 21:58:51] Energy consumed for all GPUs : 0.011695 kWh. Total GPU Power : 263.1502241810756 W\n",
      "[codecarbon INFO @ 21:58:51] Energy consumed for all CPUs : 0.001949 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 21:58:51] 0.014182 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 21:59:06] Energy consumed for RAM : 0.000587 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 21:59:06] Energy consumed for all GPUs : 0.012773 kWh. Total GPU Power : 258.89691859582024 W\n",
      "[codecarbon INFO @ 21:59:06] Energy consumed for all CPUs : 0.002126 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 21:59:06] 0.015486 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 21:59:21] Energy consumed for RAM : 0.000636 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 21:59:21] Energy consumed for all GPUs : 0.013871 kWh. Total GPU Power : 263.6244284937818 W\n",
      "[codecarbon INFO @ 21:59:21] Energy consumed for all CPUs : 0.002303 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 21:59:21] 0.016810 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 21:59:36] Energy consumed for RAM : 0.000685 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 21:59:36] Energy consumed for all GPUs : 0.014967 kWh. Total GPU Power : 263.08566677160997 W\n",
      "[codecarbon INFO @ 21:59:36] Energy consumed for all CPUs : 0.002480 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 21:59:36] 0.018131 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 21:59:51] Energy consumed for RAM : 0.000734 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 21:59:51] Energy consumed for all GPUs : 0.016056 kWh. Total GPU Power : 261.76452967162305 W\n",
      "[codecarbon INFO @ 21:59:51] Energy consumed for all CPUs : 0.002657 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 21:59:51] 0.019447 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:00:06] Energy consumed for RAM : 0.000783 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:00:06] Energy consumed for all GPUs : 0.017151 kWh. Total GPU Power : 263.10803445106194 W\n",
      "[codecarbon INFO @ 22:00:06] Energy consumed for all CPUs : 0.002834 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:00:06] 0.020768 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:00:21] Energy consumed for RAM : 0.000832 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:00:21] Energy consumed for all GPUs : 0.018243 kWh. Total GPU Power : 262.2186825220379 W\n",
      "[codecarbon INFO @ 22:00:21] Energy consumed for all CPUs : 0.003011 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:00:21] 0.022086 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:00:36] Energy consumed for RAM : 0.000881 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:00:36] Energy consumed for all GPUs : 0.019333 kWh. Total GPU Power : 261.91603899216295 W\n",
      "[codecarbon INFO @ 22:00:36] Energy consumed for all CPUs : 0.003188 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:00:36] 0.023402 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:00:51] Energy consumed for RAM : 0.000930 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:00:51] Energy consumed for all GPUs : 0.020420 kWh. Total GPU Power : 261.09099730401925 W\n",
      "[codecarbon INFO @ 22:00:51] Energy consumed for all CPUs : 0.003365 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:00:51] 0.024715 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:01:06] Energy consumed for RAM : 0.000979 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:01:06] Energy consumed for all GPUs : 0.021497 kWh. Total GPU Power : 258.49185438334746 W\n",
      "[codecarbon INFO @ 22:01:06] Energy consumed for all CPUs : 0.003542 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:01:06] 0.026017 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:01:21] Energy consumed for RAM : 0.001028 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:01:21] Energy consumed for all GPUs : 0.022583 kWh. Total GPU Power : 260.7564173863467 W\n",
      "[codecarbon INFO @ 22:01:21] Energy consumed for all CPUs : 0.003719 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:01:21] 0.027329 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:01:36] Energy consumed for RAM : 0.001076 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:01:36] Energy consumed for all GPUs : 0.023657 kWh. Total GPU Power : 258.07727171983447 W\n",
      "[codecarbon INFO @ 22:01:36] Energy consumed for all CPUs : 0.003896 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:01:36] 0.028630 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:01:51] Energy consumed for RAM : 0.001125 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:01:51] Energy consumed for all GPUs : 0.024734 kWh. Total GPU Power : 258.4494276282391 W\n",
      "[codecarbon INFO @ 22:01:51] Energy consumed for all CPUs : 0.004073 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:01:51] 0.029932 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:02:06] Energy consumed for RAM : 0.001174 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:02:06] Energy consumed for all GPUs : 0.025822 kWh. Total GPU Power : 261.2928549805971 W\n",
      "[codecarbon INFO @ 22:02:06] Energy consumed for all CPUs : 0.004250 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:02:06] 0.031246 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:02:21] Energy consumed for RAM : 0.001223 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:02:21] Energy consumed for all GPUs : 0.026913 kWh. Total GPU Power : 262.08392075124095 W\n",
      "[codecarbon INFO @ 22:02:21] Energy consumed for all CPUs : 0.004427 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:02:21] 0.032563 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:02:36] Energy consumed for RAM : 0.001272 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:02:36] Energy consumed for all GPUs : 0.027991 kWh. Total GPU Power : 259.00605020560795 W\n",
      "[codecarbon INFO @ 22:02:36] Energy consumed for all CPUs : 0.004604 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:02:36] 0.033868 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:02:51] Energy consumed for RAM : 0.001321 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:02:51] Energy consumed for all GPUs : 0.029062 kWh. Total GPU Power : 257.00956396024753 W\n",
      "[codecarbon INFO @ 22:02:51] Energy consumed for all CPUs : 0.004781 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:02:51] 0.035164 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:03:06] Energy consumed for RAM : 0.001370 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:03:06] Energy consumed for all GPUs : 0.030139 kWh. Total GPU Power : 258.7576954881379 W\n",
      "[codecarbon INFO @ 22:03:06] Energy consumed for all CPUs : 0.004958 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:03:06] 0.036467 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:03:21] Energy consumed for RAM : 0.001419 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:03:21] Energy consumed for all GPUs : 0.031201 kWh. Total GPU Power : 255.13958393837726 W\n",
      "[codecarbon INFO @ 22:03:21] Energy consumed for all CPUs : 0.005135 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:03:21] 0.037756 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:03:36] Energy consumed for RAM : 0.001468 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:03:36] Energy consumed for all GPUs : 0.032278 kWh. Total GPU Power : 258.55689963604453 W\n",
      "[codecarbon INFO @ 22:03:36] Energy consumed for all CPUs : 0.005313 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:03:36] 0.039059 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:03:51] Energy consumed for RAM : 0.001517 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:03:51] Energy consumed for all GPUs : 0.033350 kWh. Total GPU Power : 257.2712834993086 W\n",
      "[codecarbon INFO @ 22:03:51] Energy consumed for all CPUs : 0.005490 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:03:51] 0.040356 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:04:06] Energy consumed for RAM : 0.001566 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:04:06] Energy consumed for all GPUs : 0.034432 kWh. Total GPU Power : 259.9979311258935 W\n",
      "[codecarbon INFO @ 22:04:06] Energy consumed for all CPUs : 0.005667 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:04:06] 0.041664 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:04:21] Energy consumed for RAM : 0.001615 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:04:21] Energy consumed for all GPUs : 0.035513 kWh. Total GPU Power : 259.63393910432086 W\n",
      "[codecarbon INFO @ 22:04:21] Energy consumed for all CPUs : 0.005844 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:04:21] 0.042971 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:04:36] Energy consumed for RAM : 0.001663 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:04:36] Energy consumed for all GPUs : 0.036578 kWh. Total GPU Power : 255.71793248553283 W\n",
      "[codecarbon INFO @ 22:04:36] Energy consumed for all CPUs : 0.006021 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:04:36] 0.044262 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:04:51] Energy consumed for RAM : 0.001712 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:04:51] Energy consumed for all GPUs : 0.037646 kWh. Total GPU Power : 256.6544188010125 W\n",
      "[codecarbon INFO @ 22:04:51] Energy consumed for all CPUs : 0.006198 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:04:51] 0.045556 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:05:06] Energy consumed for RAM : 0.001761 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:05:06] Energy consumed for all GPUs : 0.038734 kWh. Total GPU Power : 261.2894650442337 W\n",
      "[codecarbon INFO @ 22:05:06] Energy consumed for all CPUs : 0.006375 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:05:06] 0.046870 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:05:21] Energy consumed for RAM : 0.001810 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:05:21] Energy consumed for all GPUs : 0.039820 kWh. Total GPU Power : 260.9120517335483 W\n",
      "[codecarbon INFO @ 22:05:21] Energy consumed for all CPUs : 0.006552 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:05:21] 0.048182 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:05:36] Energy consumed for RAM : 0.001859 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:05:36] Energy consumed for all GPUs : 0.040886 kWh. Total GPU Power : 255.91470278010397 W\n",
      "[codecarbon INFO @ 22:05:36] Energy consumed for all CPUs : 0.006729 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:05:36] 0.049474 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:05:55] Energy consumed for RAM : 0.001923 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:05:55] Energy consumed for all GPUs : 0.041826 kWh. Total GPU Power : 172.3707683396991 W\n",
      "[codecarbon INFO @ 22:05:55] Energy consumed for all CPUs : 0.006961 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:05:55] 0.050711 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:06:10] Energy consumed for RAM : 0.001972 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:06:10] Energy consumed for all GPUs : 0.042432 kWh. Total GPU Power : 145.50198740912592 W\n",
      "[codecarbon INFO @ 22:06:10] Energy consumed for all CPUs : 0.007138 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:06:10] 0.051542 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:06:25] Energy consumed for RAM : 0.002021 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:06:25] Energy consumed for all GPUs : 0.043471 kWh. Total GPU Power : 249.75681205068676 W\n",
      "[codecarbon INFO @ 22:06:25] Energy consumed for all CPUs : 0.007315 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:06:25] 0.052807 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:06:40] Energy consumed for RAM : 0.002070 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:06:40] Energy consumed for all GPUs : 0.044537 kWh. Total GPU Power : 255.94056680242005 W\n",
      "[codecarbon INFO @ 22:06:40] Energy consumed for all CPUs : 0.007492 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:06:40] 0.054098 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:06:55] Energy consumed for RAM : 0.002119 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:06:55] Energy consumed for all GPUs : 0.045601 kWh. Total GPU Power : 255.57408540339904 W\n",
      "[codecarbon INFO @ 22:06:55] Energy consumed for all CPUs : 0.007669 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:06:55] 0.055389 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:07:10] Energy consumed for RAM : 0.002168 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:07:10] Energy consumed for all GPUs : 0.046685 kWh. Total GPU Power : 260.309168068049 W\n",
      "[codecarbon INFO @ 22:07:10] Energy consumed for all CPUs : 0.007846 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:07:10] 0.056699 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:07:25] Energy consumed for RAM : 0.002217 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:07:25] Energy consumed for all GPUs : 0.047756 kWh. Total GPU Power : 257.30033323033723 W\n",
      "[codecarbon INFO @ 22:07:25] Energy consumed for all CPUs : 0.008023 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:07:25] 0.057996 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:07:40] Energy consumed for RAM : 0.002266 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:07:40] Energy consumed for all GPUs : 0.048837 kWh. Total GPU Power : 259.7999931441597 W\n",
      "[codecarbon INFO @ 22:07:40] Energy consumed for all CPUs : 0.008200 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:07:40] 0.059303 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:07:55] Energy consumed for RAM : 0.002314 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:07:55] Energy consumed for all GPUs : 0.049909 kWh. Total GPU Power : 257.4150001002917 W\n",
      "[codecarbon INFO @ 22:07:55] Energy consumed for all CPUs : 0.008377 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:07:55] 0.060601 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:08:10] Energy consumed for RAM : 0.002363 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:08:10] Energy consumed for all GPUs : 0.050993 kWh. Total GPU Power : 260.2670830106668 W\n",
      "[codecarbon INFO @ 22:08:10] Energy consumed for all CPUs : 0.008554 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:08:10] 0.061911 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:08:25] Energy consumed for RAM : 0.002412 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:08:25] Energy consumed for all GPUs : 0.052079 kWh. Total GPU Power : 260.930616389781 W\n",
      "[codecarbon INFO @ 22:08:25] Energy consumed for all CPUs : 0.008731 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:08:25] 0.063223 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:08:40] Energy consumed for RAM : 0.002461 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:08:40] Energy consumed for all GPUs : 0.053173 kWh. Total GPU Power : 262.6112415052228 W\n",
      "[codecarbon INFO @ 22:08:40] Energy consumed for all CPUs : 0.008908 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:08:40] 0.064542 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:08:55] Energy consumed for RAM : 0.002510 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:08:55] Energy consumed for all GPUs : 0.054257 kWh. Total GPU Power : 259.52134013747843 W\n",
      "[codecarbon INFO @ 22:08:55] Energy consumed for all CPUs : 0.009086 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:08:55] 0.065854 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:09:10] Energy consumed for RAM : 0.002559 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:09:10] Energy consumed for all GPUs : 0.055352 kWh. Total GPU Power : 261.87250769298726 W\n",
      "[codecarbon INFO @ 22:09:10] Energy consumed for all CPUs : 0.009264 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:09:10] 0.067176 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:09:25] Energy consumed for RAM : 0.002608 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:09:25] Energy consumed for all GPUs : 0.056423 kWh. Total GPU Power : 257.15715716943436 W\n",
      "[codecarbon INFO @ 22:09:25] Energy consumed for all CPUs : 0.009441 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:09:25] 0.068472 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:09:40] Energy consumed for RAM : 0.002657 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:09:40] Energy consumed for all GPUs : 0.057509 kWh. Total GPU Power : 260.8711259745778 W\n",
      "[codecarbon INFO @ 22:09:40] Energy consumed for all CPUs : 0.009618 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:09:40] 0.069785 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:09:55] Energy consumed for RAM : 0.002706 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:09:55] Energy consumed for all GPUs : 0.058588 kWh. Total GPU Power : 259.06948790319433 W\n",
      "[codecarbon INFO @ 22:09:55] Energy consumed for all CPUs : 0.009795 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:09:55] 0.071089 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:10:10] Energy consumed for RAM : 0.002755 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:10:10] Energy consumed for all GPUs : 0.059652 kWh. Total GPU Power : 255.67010844443283 W\n",
      "[codecarbon INFO @ 22:10:10] Energy consumed for all CPUs : 0.009972 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:10:10] 0.072379 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:10:25] Energy consumed for RAM : 0.002804 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:10:25] Energy consumed for all GPUs : 0.060726 kWh. Total GPU Power : 258.07060169110065 W\n",
      "[codecarbon INFO @ 22:10:25] Energy consumed for all CPUs : 0.010149 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:10:25] 0.073679 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:10:40] Energy consumed for RAM : 0.002853 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:10:40] Energy consumed for all GPUs : 0.061806 kWh. Total GPU Power : 259.2751214140748 W\n",
      "[codecarbon INFO @ 22:10:40] Energy consumed for all CPUs : 0.010326 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:10:40] 0.074985 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:10:55] Energy consumed for RAM : 0.002902 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:10:55] Energy consumed for all GPUs : 0.062879 kWh. Total GPU Power : 257.7961319673066 W\n",
      "[codecarbon INFO @ 22:10:55] Energy consumed for all CPUs : 0.010503 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:10:55] 0.076284 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:11:10] Energy consumed for RAM : 0.002951 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:11:10] Energy consumed for all GPUs : 0.063967 kWh. Total GPU Power : 261.17499822196726 W\n",
      "[codecarbon INFO @ 22:11:10] Energy consumed for all CPUs : 0.010681 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:11:10] 0.077598 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:11:26] Energy consumed for RAM : 0.003000 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:11:26] Energy consumed for all GPUs : 0.065037 kWh. Total GPU Power : 256.0159620484449 W\n",
      "[codecarbon INFO @ 22:11:26] Energy consumed for all CPUs : 0.010858 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:11:26] 0.078896 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:11:41] Energy consumed for RAM : 0.003049 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:11:41] Energy consumed for all GPUs : 0.066124 kWh. Total GPU Power : 260.96714136620693 W\n",
      "[codecarbon INFO @ 22:11:41] Energy consumed for all CPUs : 0.011036 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:11:41] 0.080209 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:11:56] Energy consumed for RAM : 0.003098 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:11:56] Energy consumed for all GPUs : 0.067216 kWh. Total GPU Power : 262.98790512526 W\n",
      "[codecarbon INFO @ 22:11:56] Energy consumed for all CPUs : 0.011213 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:11:56] 0.081526 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:12:11] Energy consumed for RAM : 0.003147 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:12:11] Energy consumed for all GPUs : 0.068307 kWh. Total GPU Power : 261.9291836550971 W\n",
      "[codecarbon INFO @ 22:12:11] Energy consumed for all CPUs : 0.011390 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:12:11] 0.082843 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:12:26] Energy consumed for RAM : 0.003195 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:12:26] Energy consumed for all GPUs : 0.069388 kWh. Total GPU Power : 259.7398982701581 W\n",
      "[codecarbon INFO @ 22:12:26] Energy consumed for all CPUs : 0.011567 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:12:26] 0.084151 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:12:41] Energy consumed for RAM : 0.003244 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:12:41] Energy consumed for all GPUs : 0.070463 kWh. Total GPU Power : 258.15908079078656 W\n",
      "[codecarbon INFO @ 22:12:41] Energy consumed for all CPUs : 0.011744 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:12:41] 0.085451 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:12:56] Energy consumed for RAM : 0.003293 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:12:56] Energy consumed for all GPUs : 0.071537 kWh. Total GPU Power : 257.9662472779856 W\n",
      "[codecarbon INFO @ 22:12:56] Energy consumed for all CPUs : 0.011921 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:12:56] 0.086751 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:13:11] Energy consumed for RAM : 0.003342 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:13:11] Energy consumed for all GPUs : 0.072626 kWh. Total GPU Power : 261.46337212847203 W\n",
      "[codecarbon INFO @ 22:13:11] Energy consumed for all CPUs : 0.012098 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:13:11] 0.088066 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:13:26] Energy consumed for RAM : 0.003391 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:13:26] Energy consumed for all GPUs : 0.073712 kWh. Total GPU Power : 260.13851425325583 W\n",
      "[codecarbon INFO @ 22:13:26] Energy consumed for all CPUs : 0.012275 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:13:26] 0.089378 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:13:41] Energy consumed for RAM : 0.003440 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:13:41] Energy consumed for all GPUs : 0.074791 kWh. Total GPU Power : 259.27422291984294 W\n",
      "[codecarbon INFO @ 22:13:41] Energy consumed for all CPUs : 0.012452 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:13:41] 0.090684 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:13:56] Energy consumed for RAM : 0.003489 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:13:56] Energy consumed for all GPUs : 0.075877 kWh. Total GPU Power : 260.7010006064724 W\n",
      "[codecarbon INFO @ 22:13:56] Energy consumed for all CPUs : 0.012629 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:13:56] 0.091996 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:14:11] Energy consumed for RAM : 0.003538 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:14:11] Energy consumed for all GPUs : 0.076968 kWh. Total GPU Power : 262.0498835209573 W\n",
      "[codecarbon INFO @ 22:14:11] Energy consumed for all CPUs : 0.012807 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:14:11] 0.093313 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:14:26] Energy consumed for RAM : 0.003587 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:14:26] Energy consumed for all GPUs : 0.078047 kWh. Total GPU Power : 259.108798334746 W\n",
      "[codecarbon INFO @ 22:14:26] Energy consumed for all CPUs : 0.012984 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:14:26] 0.094618 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:14:41] Energy consumed for RAM : 0.003636 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:14:41] Energy consumed for all GPUs : 0.079125 kWh. Total GPU Power : 258.8257874199906 W\n",
      "[codecarbon INFO @ 22:14:41] Energy consumed for all CPUs : 0.013161 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:14:41] 0.095922 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:14:56] Energy consumed for RAM : 0.003685 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:14:56] Energy consumed for all GPUs : 0.080194 kWh. Total GPU Power : 256.7910815640346 W\n",
      "[codecarbon INFO @ 22:14:56] Energy consumed for all CPUs : 0.013338 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:14:56] 0.097216 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:15:11] Energy consumed for RAM : 0.003734 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:15:11] Energy consumed for all GPUs : 0.081271 kWh. Total GPU Power : 258.89953726955946 W\n",
      "[codecarbon INFO @ 22:15:11] Energy consumed for all CPUs : 0.013515 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:15:11] 0.098520 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:15:26] Energy consumed for RAM : 0.003783 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:15:26] Energy consumed for all GPUs : 0.082340 kWh. Total GPU Power : 256.68035774680527 W\n",
      "[codecarbon INFO @ 22:15:26] Energy consumed for all CPUs : 0.013692 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:15:26] 0.099815 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:15:41] Energy consumed for RAM : 0.003831 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:15:41] Energy consumed for all GPUs : 0.083429 kWh. Total GPU Power : 261.69651008378935 W\n",
      "[codecarbon INFO @ 22:15:41] Energy consumed for all CPUs : 0.013869 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:15:41] 0.101130 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:15:56] Energy consumed for RAM : 0.003880 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:15:56] Energy consumed for all GPUs : 0.083957 kWh. Total GPU Power : 126.66893035563767 W\n",
      "[codecarbon INFO @ 22:15:56] Energy consumed for all CPUs : 0.014046 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:15:56] 0.101883 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:16:11] Energy consumed for RAM : 0.003929 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:16:11] Energy consumed for all GPUs : 0.084624 kWh. Total GPU Power : 160.14967885550232 W\n",
      "[codecarbon INFO @ 22:16:11] Energy consumed for all CPUs : 0.014223 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:16:11] 0.102776 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:16:26] Energy consumed for RAM : 0.003978 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:16:26] Energy consumed for all GPUs : 0.085678 kWh. Total GPU Power : 252.35330257803486 W\n",
      "[codecarbon INFO @ 22:16:26] Energy consumed for all CPUs : 0.014401 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:16:26] 0.104057 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:16:41] Energy consumed for RAM : 0.004027 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:16:41] Energy consumed for all GPUs : 0.086741 kWh. Total GPU Power : 255.22857601817967 W\n",
      "[codecarbon INFO @ 22:16:41] Energy consumed for all CPUs : 0.014578 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:16:41] 0.105346 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:16:56] Energy consumed for RAM : 0.004076 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:16:56] Energy consumed for all GPUs : 0.087825 kWh. Total GPU Power : 260.3548191129372 W\n",
      "[codecarbon INFO @ 22:16:56] Energy consumed for all CPUs : 0.014755 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:16:56] 0.106656 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:17:11] Energy consumed for RAM : 0.004125 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:17:11] Energy consumed for all GPUs : 0.088898 kWh. Total GPU Power : 257.6830066168937 W\n",
      "[codecarbon INFO @ 22:17:11] Energy consumed for all CPUs : 0.014932 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:17:11] 0.107955 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:17:26] Energy consumed for RAM : 0.004174 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:17:26] Energy consumed for all GPUs : 0.089979 kWh. Total GPU Power : 259.68845455663075 W\n",
      "[codecarbon INFO @ 22:17:26] Energy consumed for all CPUs : 0.015109 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:17:26] 0.109262 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:17:41] Energy consumed for RAM : 0.004223 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:17:41] Energy consumed for all GPUs : 0.091069 kWh. Total GPU Power : 261.7740072720083 W\n",
      "[codecarbon INFO @ 22:17:41] Energy consumed for all CPUs : 0.015286 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:17:41] 0.110578 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:17:56] Energy consumed for RAM : 0.004272 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:17:56] Energy consumed for all GPUs : 0.092137 kWh. Total GPU Power : 256.5484272617751 W\n",
      "[codecarbon INFO @ 22:17:56] Energy consumed for all CPUs : 0.015463 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:17:56] 0.111872 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:18:11] Energy consumed for RAM : 0.004321 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:18:11] Energy consumed for all GPUs : 0.093217 kWh. Total GPU Power : 259.26667951404875 W\n",
      "[codecarbon INFO @ 22:18:11] Energy consumed for all CPUs : 0.015640 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:18:11] 0.113178 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:18:26] Energy consumed for RAM : 0.004370 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:18:26] Energy consumed for all GPUs : 0.094304 kWh. Total GPU Power : 259.79818395145196 W\n",
      "[codecarbon INFO @ 22:18:26] Energy consumed for all CPUs : 0.015818 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:18:26] 0.114492 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:18:41] Energy consumed for RAM : 0.004419 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:18:41] Energy consumed for all GPUs : 0.095391 kWh. Total GPU Power : 260.9707255266226 W\n",
      "[codecarbon INFO @ 22:18:41] Energy consumed for all CPUs : 0.015995 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:18:41] 0.115805 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:18:56] Energy consumed for RAM : 0.004468 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:18:56] Energy consumed for all GPUs : 0.096475 kWh. Total GPU Power : 260.3187817348862 W\n",
      "[codecarbon INFO @ 22:18:56] Energy consumed for all CPUs : 0.016172 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:18:56] 0.117115 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:19:11] Energy consumed for RAM : 0.004517 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:19:11] Energy consumed for all GPUs : 0.097555 kWh. Total GPU Power : 259.4221477759428 W\n",
      "[codecarbon INFO @ 22:19:11] Energy consumed for all CPUs : 0.016349 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:19:11] 0.118421 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:19:26] Energy consumed for RAM : 0.004566 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:19:26] Energy consumed for all GPUs : 0.098641 kWh. Total GPU Power : 260.8886726213818 W\n",
      "[codecarbon INFO @ 22:19:26] Energy consumed for all CPUs : 0.016526 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:19:26] 0.119733 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:19:41] Energy consumed for RAM : 0.004615 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:19:41] Energy consumed for all GPUs : 0.099729 kWh. Total GPU Power : 261.24178661619925 W\n",
      "[codecarbon INFO @ 22:19:41] Energy consumed for all CPUs : 0.016703 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:19:41] 0.121047 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:19:56] Energy consumed for RAM : 0.004664 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:19:56] Energy consumed for all GPUs : 0.100813 kWh. Total GPU Power : 260.45372850428487 W\n",
      "[codecarbon INFO @ 22:19:56] Energy consumed for all CPUs : 0.016880 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:19:56] 0.122357 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:20:11] Energy consumed for RAM : 0.004713 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:20:11] Energy consumed for all GPUs : 0.101909 kWh. Total GPU Power : 262.7948894675602 W\n",
      "[codecarbon INFO @ 22:20:11] Energy consumed for all CPUs : 0.017058 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:20:11] 0.123679 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:20:26] Energy consumed for RAM : 0.004761 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:20:26] Energy consumed for all GPUs : 0.102985 kWh. Total GPU Power : 258.31806291916735 W\n",
      "[codecarbon INFO @ 22:20:26] Energy consumed for all CPUs : 0.017235 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:20:26] 0.124981 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:20:41] Energy consumed for RAM : 0.004810 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:20:41] Energy consumed for all GPUs : 0.104074 kWh. Total GPU Power : 261.6781278474052 W\n",
      "[codecarbon INFO @ 22:20:41] Energy consumed for all CPUs : 0.017412 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:20:41] 0.126296 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:20:56] Energy consumed for RAM : 0.004859 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:20:56] Energy consumed for all GPUs : 0.105140 kWh. Total GPU Power : 256.05189928454996 W\n",
      "[codecarbon INFO @ 22:20:56] Energy consumed for all CPUs : 0.017589 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:20:56] 0.127588 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:21:11] Energy consumed for RAM : 0.004908 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:21:11] Energy consumed for all GPUs : 0.106220 kWh. Total GPU Power : 259.3819044027268 W\n",
      "[codecarbon INFO @ 22:21:11] Energy consumed for all CPUs : 0.017766 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:21:11] 0.128894 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:21:26] Energy consumed for RAM : 0.004957 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:21:26] Energy consumed for all GPUs : 0.107297 kWh. Total GPU Power : 258.8090454719723 W\n",
      "[codecarbon INFO @ 22:21:26] Energy consumed for all CPUs : 0.017943 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:21:26] 0.130197 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:21:41] Energy consumed for RAM : 0.005006 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:21:41] Energy consumed for all GPUs : 0.108378 kWh. Total GPU Power : 259.52175891412463 W\n",
      "[codecarbon INFO @ 22:21:41] Energy consumed for all CPUs : 0.018120 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:21:41] 0.131503 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:21:56] Energy consumed for RAM : 0.005055 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:21:56] Energy consumed for all GPUs : 0.109459 kWh. Total GPU Power : 258.9215224631652 W\n",
      "[codecarbon INFO @ 22:21:56] Energy consumed for all CPUs : 0.018298 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:21:56] 0.132811 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:22:11] Energy consumed for RAM : 0.005104 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:22:11] Energy consumed for all GPUs : 0.110540 kWh. Total GPU Power : 259.6500699584148 W\n",
      "[codecarbon INFO @ 22:22:11] Energy consumed for all CPUs : 0.018475 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:22:11] 0.134118 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:22:26] Energy consumed for RAM : 0.005153 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:22:26] Energy consumed for all GPUs : 0.111624 kWh. Total GPU Power : 260.40278257833944 W\n",
      "[codecarbon INFO @ 22:22:26] Energy consumed for all CPUs : 0.018652 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:22:26] 0.135428 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:22:41] Energy consumed for RAM : 0.005202 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:22:41] Energy consumed for all GPUs : 0.112711 kWh. Total GPU Power : 261.0326731610784 W\n",
      "[codecarbon INFO @ 22:22:41] Energy consumed for all CPUs : 0.018829 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:22:41] 0.136741 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:22:56] Energy consumed for RAM : 0.005251 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:22:56] Energy consumed for all GPUs : 0.113806 kWh. Total GPU Power : 263.0591083414326 W\n",
      "[codecarbon INFO @ 22:22:56] Energy consumed for all CPUs : 0.019006 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:22:56] 0.138063 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:23:11] Energy consumed for RAM : 0.005300 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:23:11] Energy consumed for all GPUs : 0.114878 kWh. Total GPU Power : 257.5774982675091 W\n",
      "[codecarbon INFO @ 22:23:11] Energy consumed for all CPUs : 0.019183 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:23:11] 0.139361 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:23:26] Energy consumed for RAM : 0.005349 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:23:26] Energy consumed for all GPUs : 0.115955 kWh. Total GPU Power : 258.30717780367274 W\n",
      "[codecarbon INFO @ 22:23:26] Energy consumed for all CPUs : 0.019360 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:23:26] 0.140664 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:23:41] Energy consumed for RAM : 0.005398 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:23:41] Energy consumed for all GPUs : 0.117025 kWh. Total GPU Power : 256.96743173320147 W\n",
      "[codecarbon INFO @ 22:23:41] Energy consumed for all CPUs : 0.019537 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:23:41] 0.141960 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:23:56] Energy consumed for RAM : 0.005446 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:23:56] Energy consumed for all GPUs : 0.118102 kWh. Total GPU Power : 258.5422876950634 W\n",
      "[codecarbon INFO @ 22:23:56] Energy consumed for all CPUs : 0.019714 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:23:56] 0.143262 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:24:11] Energy consumed for RAM : 0.005495 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:24:11] Energy consumed for all GPUs : 0.119181 kWh. Total GPU Power : 259.18579121552534 W\n",
      "[codecarbon INFO @ 22:24:11] Energy consumed for all CPUs : 0.019891 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:24:11] 0.144568 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:24:26] Energy consumed for RAM : 0.005544 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:24:26] Energy consumed for all GPUs : 0.120253 kWh. Total GPU Power : 257.3108706725879 W\n",
      "[codecarbon INFO @ 22:24:26] Energy consumed for all CPUs : 0.020068 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:24:26] 0.145866 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:24:41] Energy consumed for RAM : 0.005593 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:24:41] Energy consumed for all GPUs : 0.121341 kWh. Total GPU Power : 261.31214432859286 W\n",
      "[codecarbon INFO @ 22:24:41] Energy consumed for all CPUs : 0.020245 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:24:41] 0.147179 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:24:56] Energy consumed for RAM : 0.005642 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:24:56] Energy consumed for all GPUs : 0.122408 kWh. Total GPU Power : 256.3805875065143 W\n",
      "[codecarbon INFO @ 22:24:56] Energy consumed for all CPUs : 0.020422 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:24:56] 0.148472 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:25:11] Energy consumed for RAM : 0.005691 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:25:11] Energy consumed for all GPUs : 0.123485 kWh. Total GPU Power : 258.688425421759 W\n",
      "[codecarbon INFO @ 22:25:11] Energy consumed for all CPUs : 0.020599 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:25:11] 0.149775 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:25:26] Energy consumed for RAM : 0.005740 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:25:26] Energy consumed for all GPUs : 0.124566 kWh. Total GPU Power : 259.1372293419441 W\n",
      "[codecarbon INFO @ 22:25:26] Energy consumed for all CPUs : 0.020777 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:25:26] 0.151083 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:25:41] Energy consumed for RAM : 0.005789 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:25:41] Energy consumed for all GPUs : 0.125646 kWh. Total GPU Power : 259.36893132010204 W\n",
      "[codecarbon INFO @ 22:25:41] Energy consumed for all CPUs : 0.020954 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:25:41] 0.152388 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:25:56] Energy consumed for RAM : 0.005838 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:25:56] Energy consumed for all GPUs : 0.126145 kWh. Total GPU Power : 119.85031985565978 W\n",
      "[codecarbon INFO @ 22:25:56] Energy consumed for all CPUs : 0.021131 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:25:56] 0.153113 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 22:26:03] Energy consumed for RAM : 0.005862 kWh. RAM Power : 11.751500129699707 W\n",
      "[codecarbon INFO @ 22:26:03] Energy consumed for all GPUs : 0.126312 kWh. Total GPU Power : 80.4208573290398 W\n",
      "[codecarbon INFO @ 22:26:03] Energy consumed for all CPUs : 0.021219 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 22:26:03] 0.153393 kWh of electricity used since the beginning.\n",
      "/home/ubuntu/fine-tuning/.venv/lib/python3.10/site-packages/codecarbon/output.py:168: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame.from_records([dict(data.values)])])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4500, training_loss=0.12159480693605211, metrics={'train_runtime': 1797.7969, 'train_samples_per_second': 10.012, 'train_steps_per_second': 2.503, 'total_flos': 3.842655598213939e+16, 'train_loss': 0.12159480693605211, 'epoch': 3.0})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "        output_dir=output_model,\n",
    "        per_device_train_batch_size=4,\n",
    "        optim = \"adamw_8bit\",\n",
    "        learning_rate=5e-5,\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_steps = 10,\n",
    "        save_steps=1500,\n",
    "        num_train_epochs=3,\n",
    "        fp16 = not torch.cuda.is_bf16_supported(),\n",
    "        bf16 = torch.cuda.is_bf16_supported(),\n",
    "        warmup_steps = 10,\n",
    "        seed = 3407,\n",
    "    )\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    train_dataset=dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model and the Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.save_pretrained(\"multilingual-function-calling-model-1.5b\", save_embedding_layers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('multilingual-function-calling-model-1.5b/tokenizer_config.json',\n",
       " 'multilingual-function-calling-model-1.5b/special_tokens_map.json',\n",
       " 'multilingual-function-calling-model-1.5b/vocab.json',\n",
       " 'multilingual-function-calling-model-1.5b/merges.txt',\n",
       " 'multilingual-function-calling-model-1.5b/added_tokens.json',\n",
       " 'multilingual-function-calling-model-1.5b/tokenizer.json')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"multilingual-function-calling-model-1.5b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[151647]\n",
      "[151649]\n",
      "[151648]\n",
      "[27, 509, 51433, 81, 29]\n",
      "[151646]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode(\"<oc_1>\"))\n",
    "print(tokenizer.encode(\"<oc_2>\"))\n",
    "print(tokenizer.encode(\"<oc_3>\"))\n",
    "print(tokenizer.encode(\"<oc_irr>\"))\n",
    "print(tokenizer.encode(\"<oc_end>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151646"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GenerationConfig\n",
    "\n",
    "# prompt = \"\"\"Below is the query from the users, please choose the correct function and generate the parameters to call the function.\n",
    "# Query: Create an appointment Business Lunch on 21.06.2024 at 10:00 for 120 minutes.\n",
    "# Response: \"\"\"\n",
    "\n",
    "prompt = \"\"\"Unten befindet sich der Befehl des Benutzers, wähle bitte die passende Funktion aus und generiere die Parameter für die Funktion.\n",
    "Befehl: {query}\n",
    "Antwort: \"\"\".format(query=\"Erstelle einen neuen Termin mit Dieter zum Abendessen am 21.3.23 um 18 Uhr für 2 Stunden\")\n",
    "\n",
    "early_stopping_token = \"<oc_end>\"\n",
    "eos_token_id = tokenizer.encode(early_stopping_token, add_special_tokens=False)[0]\n",
    "eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unten befindet sich der Befehl des Benutzers, wähle bitte die passende Funktion aus und generiere die Parameter für die Funktion.\n",
      "Befehl: Erstelle einen neuen Termin mit Dieter zum Abendessen am 21.3.23 um 18 Uhr für 2 Stunden\n",
      "Antwort: <oc_1>(\"Erstgespräch Mittelhochdeutsch\", \"2026-09-21\", '17:50\", 12)<oc_end>\n"
     ]
    }
   ],
   "source": [
    "generation_config = GenerationConfig(\n",
    "    penalty_alpha=0.0,\n",
    "    do_sample=False,\n",
    "    top_k=1,\n",
    "    temperature=0.0,\n",
    "    repetition_penalty=2.0,\n",
    "    max_new_tokens=64,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    eos_token_id=eos_token_id  # Set the early stopping token ID\n",
    ")\n",
    "\n",
    "trained_model = trainer.model #.to('cuda', dtype=torch.float32)\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to('cuda')\n",
    "outputs = trained_model.generate(**inputs, generation_config=generation_config)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Generate DPO/ORPO Rejected Examples from the Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dpo_df = pd.read_csv(\"german-dataset-dpo-creation.csv\", sep=\";\")\n",
    "# dpo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stopping_token = \"<oc_end>\"\n",
    "# eos_token_id = tokenizer.encode(early_stopping_token, add_special_tokens=False)[0]\n",
    "# trained_model = trainer.model.to('cuda', dtype=torch.float32)\n",
    "\n",
    "# generation_config = GenerationConfig(\n",
    "#     penalty_alpha=0.0,\n",
    "#     do_sample=False,\n",
    "#     top_k=1,\n",
    "#     temperature=0.0,\n",
    "#     repetition_penalty=2.0,\n",
    "#     max_new_tokens=64,\n",
    "#     pad_token_id=tokenizer.eos_token_id,\n",
    "#     eos_token_id=eos_token_id  # Set the early stopping token ID\n",
    "# )\n",
    "\n",
    "# def create_rejected_parameters(prompt):\n",
    "#     inputs = tokenizer(prompt, return_tensors=\"pt\").to('cuda')\n",
    "#     outputs = trained_model.generate(**inputs, generation_config=generation_config)\n",
    "#     output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "#     print(output)\n",
    "#     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dpo_df[\"completion_parameters_rejected\"] = dpo_df[\"prompt\"].apply(create_rejected_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dpo_df.to_csv(\"dpo-data.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# german_dpo_dataset = pd.read_csv(\"german-dpo-dataset.csv\", sep=\";\", names=[\"prompt\", \"chosen\", \"rejected\"], skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# german_dpo_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import Dataset\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# from trl import DPOTrainer, DPOConfig\n",
    "\n",
    "# dataset = Dataset.from_dict(german_dpo_dataset)\n",
    "# dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
